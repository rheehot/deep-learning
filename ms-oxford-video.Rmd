---
layout: page
title: xwMOOC 딥러닝
subtitle: 동영상 감정 분석
output:
  html_document: 
    keep_md: yes
  pdf_document:
    latex_engine: xelatex
mainfont: NanumGothic
---


```{r, include=FALSE}
source("tools/chunk-options.R") 
library(tidyverse)
library(dygraphs)
library(xts)
library(stringr)
library(ggplot2)
```
> ## 학습 목표 {.objectives}
>
> * 동영상 데이터를 분석하기 위한 전처리 작업을 살펴본다.
> * 동영상 데이터를 위한 R 툴체인을 구축한다.
> * 동영상 데이터를 인공지능 API에 던져 감정 변화를 분석한다.


## 1. 동영상 분석 개요

동영상은 광고를 보는 조건으로 [유튜브](https://www.youtube.com/)등을 통해 다양한 곳에서 구할 수 있다. 
동영상을 정했으면 다음 단계로 스트리밍 방식 동영상을 파일 동영상으로 변환을 한다. 파일 동영상을 로컬 컴퓨터에 
얻게 되면 동영상 편집기나 R을 포함한 다양한 도구를 통해 통계적 분석도 가능하게 된다.

적당한 크기의 동영상이 되면 이 파일을 R로 불러와서 감정분석을 위해서는 인공지능 API 
(예를 들어, [마이크로소프트 Cognitive Services](https://www.microsoft.com/cognitive-services/en-us/apis))를 통해
동영상 속 인물에 대한 감정을 받아와서 R의 강력한 그래픽 기능을 동원하여 동영상 속 인물의 감정변화를 분석하게 된다.

<img src="fig/ms-cognitive-video.png" alt="동영상 감정분석 개요" width="77%" />

## 2. 동영상 분석 툴체인

[유튜브](https://www.youtube.com/)에서 대상 분석 동영상을 선정하고 나면 다음 단계로 
url을 복사(이번 경우, [https://www.youtube.com/watch?v=KiJhWHYZkow](https://www.youtube.com/watch?v=KiJhWHYZkow))해서 
[http://www.computerhope.com/issues/ch001002.htm](http://www.computerhope.com/issues/ch001002.htm) 사이트 등을 통해서
유튜브 동영상 스트림을 동영상 파일로 변환시킨다. 

파일을 다운로드 받은 다음 [HandBrake](https://handbrake.fr/downloads.php)와 같은 동영상 편집기를 사용해서 적당한 크기로 
동영상을 편집한다. 

최종 편집된 동영상 파일을 R로 불러읽어와서 통계적 분석을 진행한다. R은 하나의 플랫폼으로 감정분석 및 동영상 분석, 시각화를 
위해 다양한 팩키지가 동원된다.

## 3. 감정분석 동영상 데이터

| 제1차 국민담화 | 제2차 국민담화 | 제2차 국민담화 | 
|-----------------------------------|-----------------------------------|-----------------------------------|
|<iframe width="320" height="180" src="https://www.youtube.com/embed/SuOJEZMPGqE" frameborder="0" allowfullscreen></iframe>|<iframe width="320" height="180" src="https://www.youtube.com/embed/KiJhWHYZkow" frameborder="0" allowfullscreen></iframe>|<iframe width="320" height="180" src="https://www.youtube.com/embed/y8RapzS-JxI" frameborder="0" allowfullscreen></iframe>|


- 제1차 국민담화 : 2016.10.25
    - [동영상](https://www.youtube.com/watch?v=SuOJEZMPGqE)
    - 전문 : [박근혜 대통령 대국민사과 전문](http://news.chosun.com/site/data/html_dir/2016/10/25/2016102502058.html)
- 제2차 국민담화 : 2016.11.04 
    - [동영상](https://www.youtube.com/watch?v=KiJhWHYZkow)
    - 전문: [박근혜 대통령 사과 대국민담화](http://news.khan.co.kr/kh_news/khan_art_view.html?artid=201611041048021)
- 제3차 국민담화 : 2016.11.29
    - [박근혜 대통령 3차 대국민 담화](http://myk.kbs.co.kr/hotclip?shortclip_id=meta_shortclip_k1_myk1_pt201600023101000e6e325be)
    - 전문 : [박근혜 대통령, 대국민 담화 전문](http://www1.president.go.kr/news/newsList2.php?srh[view_mode]=detail&srh[seq]=18402)


## 4. 동영상 감정 분석 [^microfot-ai-and-r] [^microfot-ai-and-python]

[^microfot-ai-and-r]: [Analyzing Emotions using Facial Expressions in Video with Microsoft AI and R](https://blog.exploratory.io/analyzing-emotions-using-facial-expressions-in-video-with-microsoft-ai-and-r-8f7585dd0780#.8tkpux2i2)

[^microfot-ai-and-python]: [How to apply face recognition API technology to data journalism with R and python](https://benheubl.github.io/data%20analysis/fr/)

동영상 감정분석을 위해 미국대선에서 11월에 분석된 파이썬과 R코드를 기반으로 대국민담화 동영상 데이터속 감정변화를 분석한다.

### 4.1. 기본 동영상 분석 

R에서 동영상분석을 위한 팩키지는 공식적으로 배포되는 것은 없고, [GitHub](http://github.com)을 통해 일부 개발중에 있으며 실험목적으로 활용은 가능하다.
`Rvision` 팩키지의 `video()` 함수를 사용해서 [OpenCV](http://opencv.org/) `Rcpp_Image` 객체로 만들고 나서 차원정보를 보게 되면
동영상 화면 정보와 더불어 프레임(frame) 정보를 확인한게 된다.
제3차 담화문 총 8540 프레임중 5000 번째 프레임을 추출해 보자.

``` {r eval=FALSE}
# 0. 환경설정------------------------------------------------------------------

# devtools::install_github("swarm-lab/videoplayR")
# devtools::install_github("swarm-lab/ROpenCVLite")
# devtools::install_github("swarm-lab/Rvision")
library(Rvision)

# 1. 데이터 가져오기-----------------------------------------------------------

speech_video <- video("03.data/park_speech_03_320.mp4")
dim(speech_video)
## [1]  180.0000  319.3333 8540.0000

# 2. 동영상 이미지 불러오기-----------------------------------------------------------

img_5000 <- readFrame(speech_video, 5000)
plot(img_5000)
```

<img src="fig/ms-congitive-image.png" alt="동영상에서 이미지 추출" width="77%" />

``` {r eval=FALSE}
# 0. 환경설정------------------------------------------------------------------

# devtools::install_github("swarm-lab/videoplayR")
# devtools::install_github("swarm-lab/ROpenCVLite")
# devtools::install_github("swarm-lab/Rvision")
library(Rvision)
library(tidyverse)
library(stringr)
# 1. 데이터 가져오기-----------------------------------------------------------

speech_video <- video("03.data/park_speech_03_320.mp4")
emo_df <- read_csv("03.data/park_emo_03.csv")
# scores. 변수명 제거
names(emo_df) <- str_replace(names(emo_df), "scores.", "")

# 2. 동영상 이미지 불러오기-----------------------------------------------------------
iframe <- 200
img_iframe <- readFrame(speech_video, iframe)
plot(img_iframe)

x_dim <- dim(img_iframe)[2]
y_dim <- dim(img_iframe)[1]

# 얼굴 위치 사각형 표시
with(emo_df[iframe,], 
  rect(x*x_dim, (y_dim-(y)*y_dim), (x+width)*x_dim, (y_dim-(y)*y_dim - (height)*y_dim), border = "red"))

# 다양한 감정 수치화
with(emo_df[iframe,], 
    text(x*x_dim+75, (y_dim-(y)*y_dim), bquote(paste("neutral:", .(neutral))), cex = .75, col="red"))
with(emo_df[iframe,], 
    text(x*x_dim+75, (y_dim-(y)*y_dim)-10, bquote(paste("happiness:", .(happiness))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-20, bquote(paste("surprise:", .(surprise))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-30, bquote(paste("sadness:", .(sadness))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-40, bquote(paste("anger:", .(anger))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-50, bquote(paste("disgust:", .(disgust))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-60, bquote(paste("fear:", .(fear))), cex = .75, col="red"))
with(emo_df[iframe,], 
     text(x*x_dim+75, (y_dim-(y)*y_dim)-70, bquote(paste("contempt:", .(contempt))), cex = .75, col="red"))

# 3. 동영상 + 감정 이미지-----------------------------------------------------------
# 10 개 프레임만 선택
idx <- seq(1, dim(speech_video)[3], length.out=10)

for(iframe in seq_along(idx)){
  img_iframe <- readFrame(speech_video, iframe)
  plot(img_iframe)
  
  x_dim <- dim(img_iframe)[2]
  y_dim <- dim(img_iframe)[1]
  
  with(emo_df[iframe,], 
       rect(x*x_dim, (y_dim-(y)*y_dim), (x+width)*x_dim, (y_dim-(y)*y_dim - (height)*y_dim), border = "red"))

  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim), bquote(paste("neutral:", .(neutral))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-10, bquote(paste("happiness:", .(happiness))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-20, bquote(paste("surprise:", .(surprise))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-30, bquote(paste("sadness:", .(sadness))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-40, bquote(paste("anger:", .(anger))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-50, bquote(paste("disgust:", .(disgust))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-60, bquote(paste("fear:", .(fear))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-70, bquote(paste("contempt:", .(contempt))), cex = .75, col="red"))
}


# 4. GIF 만들기-------------------------
idx <- seq(1, dim(speech_video)[3], length.out=10)

for(iframe in seq_along(idx)){
  png(filename=paste0("06.images/img_",iframe,".png"))
  img_iframe <- readFrame(speech_video, iframe)
  plot(img_iframe)
  
  x_dim <- dim(img_iframe)[2]
  y_dim <- dim(img_iframe)[1]
  
  with(emo_df[iframe,], 
       rect(x*x_dim, (y_dim-(y)*y_dim), (x+width)*x_dim, (y_dim-(y)*y_dim - (height)*y_dim), border = "red"))
  
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim), bquote(paste("neutral:", .(neutral))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-10, bquote(paste("happiness:", .(happiness))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-20, bquote(paste("surprise:", .(surprise))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-30, bquote(paste("sadness:", .(sadness))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-40, bquote(paste("anger:", .(anger))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-50, bquote(paste("disgust:", .(disgust))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-60, bquote(paste("fear:", .(fear))), cex = .75, col="red"))
  with(emo_df[iframe,], 
       text(x*x_dim+75, (y_dim-(y)*y_dim)-70, bquote(paste("contempt:", .(contempt))), cex = .75, col="red"))
  
  dev.off()
}
# GIF 만들기
library(animation)
im.convert("06.images/*.png", output = "img_animation.gif")
```

<img src="fig/img_animation.gif" alt="감정분석 애니메이션" width="100%" />

### 4.2. 감정분석 API 사용 권한 획득

<img src="fig/ms-cognitive-service-emotion-key.png" alt="동영상 감정분석 API 키" width="57%" />


``` {r emo-api-ggplot}
# 0. 환경설정------------------------------------------------------------------
# library(stringr)
# library(dplyr)

# 1. 데이터 가져오기-----------------------------------------------------------

emo_01_df <- read_csv("data/park_emo_01.csv")
emo_02_df <- read_csv("data/park_emo_02.csv")
emo_03_df <- read_csv("data/park_emo_03.csv")

# 2. 데이터 정제-----------------------------------------------------------

emo_01_df <- emo_01_df %>% mutate(speech='10-25', frame=1:length(speech)) %>% unite(speech_frame, speech, frame)
emo_02_df <- emo_02_df %>% mutate(speech='11-04', frame=1:length(speech)) %>% unite(speech_frame, speech, frame)
emo_03_df <- emo_03_df %>% mutate(speech='11-29', frame=1:length(speech)) %>% unite(speech_frame, speech, frame)

emo_df <- bind_rows(emo_01_df, emo_02_df, emo_03_df)

emo_long_df <- emo_df %>% gather(key, value, starts_with("scores")) %>%
  mutate(key = str_replace(key, "scores.", "")) %>%
  dplyr::filter(key != 'neutral')

# 3. 데이터 시각화-----------------------------------------------------------
library(ggplot2)
ggplot(emo_long_df, aes(speech_frame, value, group = key, col = key)) +
  # geom_line() +  # would display all the non-smoothed lines
  geom_smooth(method = "loess", n = 100000, se = F,  span = 0.1) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_x_discrete(breaks = c('10-25_1', '11-04_1', '11-29_1'))
```
