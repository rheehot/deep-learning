---
layout: page
title: xwMOOC 딥러닝
subtitle: $H_2 O$ 앙상블 모형
---

> ## 학습 목표 {.objectives}
>
> * $H_2 O$ 앙상블 모형을 이해한다.

### 1. 앙상블 모형

앙상블 모형은 배깅, 부스팅, 스택쌓기 등 다양한 모형조합 알고리즘이 존재한다. 

|       앙상블 모형      |              특징                                 |
|------------------------|---------------------------------------------------|
|     배깅(Bagging)      | * 분산을 줄이고, 정확도를 향상                    |
|                        | * 이상치와 잡음이 있는 데이터에 강건              |
|                        | * 흔히 의사결정나무(Decision Tree)와 함께 사용, 즉 확률숲(Random Forest) |
|------------------------|---------------------------------------------------|
|    부스팅(Boosting)    | * 분산을 줄이고, 정확도를 향상                    |
|                        | * 이상치와 잡음이 있는 데이터에 강건하지 않음     |
|                        | * 유연성 -- 어떤 유형의 손실함수와 함께 사용가능  |
|------------------------|---------------------------------------------------|
|   스택쌓기(Stacking)   | * 강력한 성능을 갖는 다양한 분류학습기를 앙상블로 조합 |
|                        | * "메타학습기(metalearner)" 알고리즘을 사용하여 다음 수준 기계학습을 통해 기초 학습기에 대한 최적의 조합을 찾아내도록 학습. |


**슈퍼학습기(Super learner)** 는 버클리 통계학과 교수 Mark van der Laan가 2007년 발표한 논문에 뿌리를 두고 있다.
물론 그 이전에 관련된 연구를 지속적으로 진행하였으며, 슈퍼학습기가 점근적으로 최적 조합이라는 것을 증명한 이론적 토대를 제공했으며 2010년 첫 R 코드로 구현되었고, [SuperLearner - Super Learner Prediction](https://cran.r-project.org/web/packages/SuperLearner/index.html), [tlme](https://cran.r-project.org/web/packages/tmle/index.html)로 CRAN에서 설치가능하다.

슈퍼학습기 이전에 David H. Wolpert가 1992년 **Stacked Generalization** 으로 메타학습기를 통한 스택쌓기를 처음 공식화했고, Leo Breiman 교수가 1996년 **Stacked Regressions** 을 제안했고, 이 연구결과가 슈퍼학습기로 이어졌다.


### 2. 슈퍼학습기 알고리즘

**"수준 0(Level-zero)"** 데이터는 전통적인 통계모형에 사용된 데이터 형태로 이해하면 쉽다.
즉, 설계행렬 $X$와 종속변수 $y$로 모형 모수와 함께 기본 학습기를 지정한다. 필요하면 다른 알고리즘을 지정해서 메타 학습기를 지정하기도 한다. 그리고 나서 k-집단 교차타당도를 기본학습기에 적용하여 성능을 평가한다.

<img src="fig/h2o_level_zero.png" alt="수준 0 데이터" width="25%">

**"수준 1(Level-One)"** 데이터는 k-집단 교차타당도를 적용한 기본학습기에서 나온 예측값을 수집한다.
이를 칼럼마다 모아 새로운 설계 행렬 $Z$를 생성한다. $Z$, $y$를 사용해서 메타학습기를 훈련시켜 최적 모형을 개발한다.

<img src="fig/h2o_level_one.png" alt="수준 1 데이터" width="60%">

슈퍼학습기는 교차타당도를 통해 다른 모수를 갖는 다양한 모형을 명세하여 모형선택과정을 거친다는 점에서 격자탐색(Grid Search)과 임의탐색(Random Search) 과정을 거치는 모수 미세조정, 모수 탐색 방법론과 맥을 함께 한다.
하지만, 메타러닝 단계로 알려진 슈퍼학습기 알고리즘 후반부는 또다른 모형을 하나 생성한다는 점에서 차별점이 있다.
 

